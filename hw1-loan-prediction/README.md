# HW1. Loan Approval Prediction 

[Ссылка на Colab](https://colab.research.google.com/drive/1KVeB47Hq7xLsFuiJ20NUErzHNR7EtYQS#scrollTo=eUeos_DArV7Q)
## Эксперимент 1. Простая модель 

### Как ведёт себя модель по мере обучения? Сколько эпох оптимально?

`Train Loss=0.2270, Train ROC-AUC=0.9046, Eval Loss=0.2186, Eval ROC-AUC=0.9162`

По мере обучения метрики лосса падают, а ROC-AUC растёт (хоть темпы со временем падают). 
Следовательно, даже при большом кол-ве эпох модель не переобучается. 
Скорее всего, это связано с тем, что пока модель слишком простая и недообучается

![1-10.png](images%2F1-10.png)
![1-50.png](images%2F1-50.png)

## Эксперимент 2. Модель побольше

### Стало ли лучше? Как теперь ведёт себя модель?

`Train Loss=0.2193, Train ROC-AUC=0.9089, Eval Loss=0.2122, Eval ROC-AUC=0.9214`

Увеличение сложности модели позволило повысить метрики

![2.png](images%2F2.png)

## Эксперимент 3. Skip Connections, Batch Norms

### Стало ли лучше? Как теперь ведёт себя модель?

`Train Loss=0.2199, Train ROC-AUC=0.9108, Eval Loss=0.2346, Eval ROC-AUC=0.9119`

Как ни странно, но метрики немного упали. Возможно, взят неоптимальный lr для новой модели

![3.png](images%2F3.png)

## Эксперимент 4. Dropout

### Как меняется качество модели в зависимости от p? Как ведёт себя модель с разными p?

`Train Loss=0.2393, Train ROC-AUC=0.8972, Eval Loss=0.2352, Eval ROC-AUC=0.9137`

dropout=0.01 дал лучшие метрики. Большие значения оказались избыточными, 
что можно объяснить небольшим кол-во слоёв в исходной модели. 
При больших значениях модель забывала полезную информацию с предыдущих слоёв

![3.png](images%2F3.png)

## Эксперимент 5. Weight Decay, Learning Rate

### Как зависит качество итоговой модели от этих двух параметров? Как ведёт себя модель с разными lambda и lr?

`Train Loss=0.2067, Train ROC-AUC=0.9176, Eval Loss=0.2076, Eval ROC-AUC=0.9229`

Лучшего всего модель показала себя с lr=0.1, weight_decay=0.001. Однако, это скорее удачное попадание в локальный минимум.
При lr=0.001 результаты были более предсказуемыми. На всех тестах weight_decay=0.001 давал лучший результат, т.к наша модель не склонна к переобучению

![5.png](images%2F5.png)